# Module 3 Blog

Though I had some trouble with downloading Java JRE and OpenRefine, this module went smoothly for me overall. I was able to complete all of the exercises this time, though I opted not to do the optional Going Further exercises because I was running out of time.

## Exercises

### Exercise 1

Overall, this exercise went well. I used Nano to delete the irrelevant text that came before the index, but I used TextEdit to do the remaining irrelevant text because it was faster, and I could also see the progress I was making. While I was trying to figure out the correct command for step 3, my DHBox malfunctioned, so I wasn't able to save my history before this point. Because of this, the command history recorded in Module3-Commands.md doesn't reflect the first 2 steps. The malfunction came after I exited Nano and my cursor was stuck a few lines above where it was supposed to be. I refreshed DHBox and sent a message in Slack to see if anyone had any advice, and I learned from Maggie Sherwin and Dr. Graham that I can type either ```clear``` or ctrl+l to clear the screen the next time this happens. 

It took me some time to figure out what the right command was for step 3. I had worked it out to be ```sed -r -i.bak 's/(,)( [[0-9]{4})(.+)/\2/g' index.txt```, which was correct but I didn't know that right away. I was trying to use RegExr to try the command out before I actually typed it into DHBox, but I didn't understand how RegExr worked or why I couldn't put the "s" before the first forward slash. Also, I didn't know what the "Tools" section is for. I thought that this meant that I had the command wrong and I racked my brains trying to come up with something else. When I couldn't, I watched the instructional video so I could figure out what I was missing and learned that I actually had it right, and I was able to move along. 

In step 5, after successfully replacing every "to" with a comma, I opened Nano to make sure everything looked right. I noticed that there weren't spaces after the first comma of each line but that there were spaces after the second comma. I thought this might be important for the next steps, that it might trip up the machine, so I tried to fix it. It was too tedious to try to add a space to each line in TextEdit, so I attempted to do this in the command line. I ended up switching it from commas to "(, )", then to "(,)", and then just "()". I had to Google how to write a command so that brackets were identified as the thing I wanted to replace, except I didn't do it quite right and ended up with ",," after that. But, I was able to easily construct a final find and replace command to go from ",," to just one comma. After this, I was still missing that space after the first comma, but I decided to keep going and see if it even mattered, and to only keep tinkering with it if it did matter. 

In step 6, when I typed ```grep -r ".+,.+,.+," index.txt``` nothing happened in Nano. I watched the instructional video and saw that they had typed just the middle part into RegExr, not the command line, so I did the same. This worked perfectly, and the conversion into a .csv file went well too. The instructions at this step were to make a note about the .csv file when uploading it. I put my note in the optional comments box of the commit screen, but I will add it here as well. The original location of the file is the File Manager in DHBox. The changes I made included clearing out irrelevant text and page numbers, and replacing each "to" with a comma. I also added column headers and then converted the file to .csv. This exercise was done over the course of two days and finished at 12:30pm on June 1.

### Exercise 2

I had trouble setting up Java JRE. I went on Java's website and downloaded the program. I then opened Safari, as per Java's instructions, and used Java's verifier to see if it successfully installed. I got a message that the plug-in wasn't supported, and was also told I need to click Run, but there was nowhere to do this. I opened a page that provided more information about using Java with different browsers, and it told me that all of the browsers I use - Firefox, Chrome, and Safari - could not support it. I posted a question in Slack to see if anyone knew what I should do, and Dr. Graham helped me out. He had me try a few direct links to see if they might help, and also use my terminal to see what information it might provide. When these things still didn't make Java work, he told me to just leave it for the time being and download OpenRefine. Apple tried to block me from opening it because it was from an unidentified developer, but Dr. Graham told me to hold down the control key when I opened it to bypass this, and it worked.

When I uploaded my .csv file to OpenRefine, my data wasn't separated into columns like it's supposed to be. However, when I open the .csv file in Numbers on my computer, it's in a table, so I was confused. I sent a question into Slack to see if this had happened to anyone else. Jeffrey told me to make sure I checked off comma separated values, so I made a new project, checked this off, and it worked. Cleaning up the sender and recipient lists went well. It took some Googling to figure out which spellings were right for some of them. I ended up with more senders and recipients left than we were supposed to have. I had 165 senders and 180 recipients, but the workbook said we should have roughly 150 senders and 160 recipients. I'm not sure why this is different but I couldn't see anymore names I could merge, so I moved on. 

When I loaded my edited .csv file into Palladio, I was surprised by how connected most of the recipients and senders were in the graph. I was also surprised to find that there were some senders and recipients who had interacted only with each other, and were offset from the crowded part of the graph.

### Capstone Exercise

This week I started the capstone exercise. I'm a little bit uncertain about what is expected of me for this assignment, but I'm going to thoroughly reread the manual and see if that helps, and if not I will turn to Slack. I did already ask in Slack if we were supposed to already have transcribed the Canadian war diaries because the instructions in this module gave that impression. Dr. Graham clarified that it's just prompting us to start thinking about the final assignment. I decided that a good place to start is to download all of the war diaries off of DHBox and give them descriptive file names. At the same time, I will read through each one and get an idea of what they are about and what I can do with them. This has been a slow and tedious process, and at the time of submission, I haven't finished it yet.

## Annotations

I chose to do my official annotations on David J. Birnbaum's "What is XML and why should humanists care? An even gentler introduction to XML". This article explained XML really well and clearly and I feel much more confident in my understanding of it now. 

All of my annotations for this article start with a note identifying which sentence I am intending to annotate to make sure there is no confusion, because the website kept showing sentences other than the ones I was highlighting.

### Annotation 1

In this [annotation](https://hyp.is/bUs6KIM_Eem6S7OYAyAd4A/dh.obdurodon.org/what-is-xml.xhtml), I reflected on the importance of handling the data you collect for a project with thoughtfulness, to make sure you can make it accessible for future use. Digital history isn't all that different from regular history, at least in this sense, because even if you're just keeping handwritten notes somewhere in your office, you still want them to be legible and organized so that future you can get information out of them. The same applies to organizing digital data. I had never heard of XML before this course, but after reading this article, I understand the many benefits to using XML as a way to effectively store your data. I also connected this annotation to Beals' "XMLing My Way to Data Management; or, What should I do with all my old notes" because her writing added another layer of understanding for me. She explained how other ways of storing data, such as an Access database, were faulty because, as programs fall out of use and new ones are developed, formatting can be lost in the transfer from one database to another. Therefore, it is important to consider your future needs when you're organizing your data, to save future you much time and trouble.

### Annotation 2

In this second [annotation](https://hyp.is/xsrGZoL7EemPtO8yBOd78A/dh.obdurodon.org/what-is-xml.xhtml), I learned more about what XSL is. I had been unsure of why we needed the XSL document in Module 2 to make the XML document work. The sentence I annotated here is part of a paragraph discussing XML validation. When I read this, I wondered if our XSL document had been used to validate the XML document we produced. I then learned the answer to this question when I switched to the Exercises page of Module 3. In the first paragraph, a brief explanation is given: that XSL adds styles to XML. After learning this, I thought back to the exercises in Module 2 and about how my file had changed when I dragged it into Firefox, and that process makes a lot more sense to me now. I also learned that XSL has nothing to do with validating like I originally thought.

### Annotation 3

In this final [annotation](https://hyp.is/J3lUAoL6EemQB_dn2HtgvQ/dh.obdurodon.org/what-is-xml.xhtml), I expressed confusion about an example of poorly-formed XML that Birnbaum corrected. He explained that it was incorrect because there wasn't one root in which the tags dairy and snacks sat. But I had thought that each tag had to be indented and nested within another, and that there could not be more than one tag at an indent. I Googled this question and found this [website](https://www.w3resource.com/xml/proper-nesting-of-elements.php), and learned that more than one tag can sit within another tag. So, I understand XML just a bit better now. 

## Reflection Questions

### On your blog, reflect on any data cleaning you've had to do in other classes. Why don't historians discuss this kind of work? What gets hidden, what gets lost, how is the ultimate argument weaker as a result? Or does it matter? Make reference (or link to) key annotations, whether by you or one of your peers, to support your points.

I haven't had to do any data cleaning for other classes, but I imagine historians don't discuss this because it seems more like a tedious task that often has to be done before getting to more interesting work. Or, if they do discuss it, it would be to complain about something, like how much time it's taking. But I think it could be important to discuss the process of data cleaning because, otherwise, you might miss out on helpful or interesting information. I think that discussing data cleaning can go hand-in-hand with open notebook practices, in the sense that you may assume some information is wrong and disregard it or delete it, when actually you interpreted it incorrectly, for example. A few weeks ago, I reflected on the value of sharing your notes publically. Dr. Graham [replied](https://hyp.is/EUuZonf6EemR7jN9nr9o7Q/wcm1.web.rice.edu/open-notebook-history.html) and mentioned that some people use Zotero to keep publically-available bibliographies. This makes me think that perhaps someone might explore another's bibliography and point out any information the poster thought was wrong. Without engaging in discussions like this, useful, or even critical, evidence may be missed, potentially making an argument weaker. 
